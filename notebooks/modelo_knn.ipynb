{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/airline_passenger_satisfaction.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar las Características (X) y la Etiqueta (y)\n",
    "\n",
    "+ y = satisfaction (variable a predecir)\n",
    "* X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['satisfaction'])\n",
    "y = df['satisfaction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento de Datos\n",
    "\n",
    "Identificación de Columnas Categóricas y Numéricas\n",
    "\n",
    "* categorical_features: Se identifican las columnas que contienen datos categóricos (como texto).\n",
    "\n",
    "* numerical_features: Se identifican las columnas con datos numéricos.\n",
    "\n",
    "* ColumnTransformer: Nos permite aplicar diferentes transformaciones a diferentes columnas. Aquí se están aplicando dos transformaciones:\n",
    "\n",
    "    * StandardScaler: Escala las columnas numéricas para que tengan media 0 y desviación estándar 1 (normalización).\n",
    "    \n",
    "    * OneHotEncoder: Convierte las variables categóricas en variables dummy (0 y 1), eliminando la primera categoría para evitar la multicolinealidad (equivalente a drop_first=True en pd.get_dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "# Imputación de datos faltantes (si fuera necesario)\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "X[numerical_features] = imputer_num.fit_transform(X[numerical_features])\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "X[categorical_features] = imputer_cat.fit_transform(X[categorical_features])\n",
    "\n",
    "# Escalado de las características numéricas\n",
    "scaler = StandardScaler()\n",
    "X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "\n",
    "# Codificación de las características categóricas\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificación de las características categóricas\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# Concatenar las características numéricas escaladas con las categóricas codificadas\n",
    "X = np.hstack((X[numerical_features].values, X_encoded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividir el Conjunto de Datos\n",
    "\n",
    "Se divide el dataset en conjuntos de entrenamiento y prueba:\n",
    "\n",
    "* X_train, y_train: Se utilizan para entrenar el modelo (80% de los datos).\n",
    "\n",
    "* X_test, y_test: Se utilizan para evaluar el modelo (20% de los datos).\n",
    "\n",
    "* test_size=0.20: Indica que el 20% de los datos se reservarán para pruebas.\n",
    "\n",
    "* random_state=0: Para asegurar que la división sea reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el dataset en conjunto de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrenamiento del Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Entrenar el modelo K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación del Modelo (Predicciones)\n",
    "\n",
    "Se hacen predicciones sobre el conjunto de prueba usando el modelo entrenado.\n",
    "\n",
    "* Informe de Clasificación y Matriz de Confusión\n",
    "\n",
    "    * classification_report: Muestra varias métricas de evaluación, como precisión (accuracy), recall, F1-score, etc.\n",
    "\n",
    "    * confusion_matrix: Muestra la matriz de confusión, que ayuda a entender cómo de bien el modelo está clasificando las etiquetas correctas frente a las incorrectas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curva ROC y AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC y AUC\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "# Convertir etiquetas a valores binarios\n",
    "y_test_binary = y_test.map({'neutral or dissatisfied': 0, 'satisfied': 1})\n",
    "\n",
    "# Obtener las probabilidades predichas para la clase positiva\n",
    "y_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular la curva ROC utilizando las etiquetas binarias\n",
    "fpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Graficar la curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validación Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Guardar el modelo entrenado para producción\n",
    "import joblib\n",
    "\n",
    "\n",
    "joblib.dump(knn, 'knn_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
